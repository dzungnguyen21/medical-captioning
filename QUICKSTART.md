# Quick Start Guide

HÆ°á»›ng dáº«n nhanh Ä‘á»ƒ báº¯t Ä‘áº§u vá»›i há»‡ thá»‘ng Image Captioning.

## ğŸ“¦ BÆ°á»›c 1: CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

```bash
# Clone repository
cd d:\AI\medical_img_captioning_train

# Táº¡o virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt

# CÃ i Ä‘áº·t Detectron2
pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu117/torch2.0/index.html

# CÃ i Ä‘áº·t COCO evaluation tools
pip install pycocoevalcap
```

## ğŸ“Š BÆ°á»›c 2: Chuáº©n bá»‹ dá»¯ liá»‡u

### General Domain (MS-COCO)

```bash
# Táº£i MS-COCO dataset
mkdir -p data/COCO
cd data/COCO

# Download images
wget http://images.cocodataset.org/zips/train2014.zip
wget http://images.cocodataset.org/zips/val2014.zip

# Unzip
unzip train2014.zip
unzip val2014.zip

# Download Karpathy split
wget https://cs.stanford.edu/people/karpathy/deepimagesent/caption_datasets.zip
unzip caption_datasets.zip
```

### Medical Domain (MIMIC-CXR)

```bash
# MIMIC-CXR requires PhysioNet credentialing
# Visit: https://physionet.org/content/mimic-cxr/2.0.0/

# After obtaining access:
mkdir -p data/MIMIC-CXR
cd data/MIMIC-CXR

# Download using wget with credentials
wget -r -N -c -np --user YOUR_USERNAME --ask-password https://physionet.org/files/mimic-cxr/2.0.0/
```

## ğŸš€ BÆ°á»›c 3: Training

### Option A: Training tá»« Ä‘áº§u (General Domain)

```bash
# Phase 1: Supervised Training (30 epochs, ~12 hours on single GPU)
python General_Domain/train_general.py \
    --data_dir ./data/COCO \
    --checkpoint_dir ./checkpoints/general \
    --epochs_xe 30 \
    --batch_size 32 \
    --device cuda \
    --skip_rl

# Phase 2: RL Training (20 epochs, ~8 hours)
python General_Domain/train_general.py \
    --data_dir ./data/COCO \
    --checkpoint_dir ./checkpoints/general \
    --epochs_rl 20 \
    --batch_size 32 \
    --device cuda \
    --skip_xe
```

### Option B: Training tá»« Ä‘áº§u (Medical Domain)

```bash
# Phase 1: Supervised Training (50 epochs, ~24 hours)
python Medical_Domain/train_medical.py \
    --data_dir ./data/MIMIC-CXR \
    --checkpoint_dir ./checkpoints/medical \
    --epochs_xe 50 \
    --batch_size 16 \
    --device cuda \
    --skip_rl

# Phase 2: RL Training with RadGraph (30 epochs, ~15 hours)
python Medical_Domain/train_medical.py \
    --data_dir ./data/MIMIC-CXR \
    --checkpoint_dir ./checkpoints/medical \
    --epochs_rl 30 \
    --batch_size 16 \
    --use_radgraph \
    --device cuda \
    --skip_xe
```

### Option C: Training vá»›i config files

```bash
# Sá»­ dá»¥ng YAML configs
python General_Domain/train_general.py --config configs/general_config.yaml
python Medical_Domain/train_medical.py --config configs/medical_config.yaml
```

## ğŸ“ˆ BÆ°á»›c 4: Evaluation

### Evaluate General Domain

```bash
python General_Domain/evaluate_general.py \
    --checkpoint ./checkpoints/general/best_rl_model.pth \
    --data_dir ./data/COCO \
    --output_dir ./results/general \
    --dataset coco \
    --split test \
    --beam_size 3
```

**Káº¿t quáº£ mong Ä‘á»£i:**
```
BLEU-4: 0.378
CIDEr: 126.7
CHAIR_i: 0.052
CHAIR_s: 0.121
```

### Evaluate Medical Domain

```bash
python Medical_Domain/evaluate_medical.py \
    --checkpoint ./checkpoints/medical/best_rl_model.pth \
    --data_dir ./data/MIMIC-CXR \
    --output_dir ./results/medical \
    --dataset mimic_cxr \
    --split test \
    --beam_size 3 \
    --use_radgraph
```

**Káº¿t quáº£ mong Ä‘á»£i:**
```
BLEU-4: 0.153
CIDEr: 39.8
RadGraph F1: 0.361
```

## ğŸ¨ BÆ°á»›c 5: Inference (Demo)

### Python Script

```python
from demo_inference import ImageCaptioner

# General domain
captioner = ImageCaptioner(
    checkpoint_path='./checkpoints/general/best_rl_model.pth',
    domain='general',
    device='cuda'
)

caption = captioner.generate_caption('path/to/image.jpg', beam_size=3)
print(f"Caption: {caption}")

# Visualize
captioner.visualize('path/to/image.jpg')
```

### Medical domain

```python
medical_captioner = ImageCaptioner(
    checkpoint_path='./checkpoints/medical/best_rl_model.pth',
    domain='medical',
    device='cuda'
)

report = medical_captioner.generate_caption('path/to/xray.dcm', beam_size=3)
print(f"Report: {report}")
```

## ğŸ”§ BÆ°á»›c 6: Troubleshooting

### CUDA Out of Memory

```bash
# Giáº£m batch size
--batch_size 8

# Giáº£m sá»‘ regions
--num_regions 20

# Use gradient accumulation (sá»­a trong trainer.py)
```

### Slow Training

```bash
# Sá»­ dá»¥ng mixed precision training (thÃªm vÃ o trainer)
from torch.cuda.amp import autocast, GradScaler

# TÄƒng num_workers
--num_workers 8

# Pre-extract features (táº¡o file .h5)
```

### RadGraph/CheXbert khÃ´ng hoáº¡t Ä‘á»™ng

```bash
# Install RadGraph dependencies
pip install radgraph
python -m spacy download en_core_sci_sm

# Skip medical metrics náº¿u khÃ´ng cáº§n
--use_radgraph False
--use_chexbert False
```

## ğŸ“Š BÆ°á»›c 7: Monitoring Training

### TensorBoard

```bash
# ThÃªm vÃ o training scripts:
from torch.utils.tensorboard import SummaryWriter
writer = SummaryWriter('./logs')

# Xem training progress
tensorboard --logdir=./logs
```

### Weights & Biases (Optional)

```bash
# Install wandb
pip install wandb

# Login
wandb login

# Enable trong config
use_wandb: true
wandb_project: "my-captioning-project"
```

## ğŸ¯ BÆ°á»›c 8: Thá»­ nghiá»‡m vá»›i cÃ¡c cáº¥u hÃ¬nh khÃ¡c

### Ablation Study: Chá»‰ dÃ¹ng CIDEr reward

```bash
python General_Domain/train_general.py \
    --reward_cider_weight 1.0 \
    --reward_chair_weight 0.0 \
    --skip_xe
```

### Thá»­ nghiá»‡m vá»›i model nhá» hÆ¡n

```bash
python General_Domain/train_general.py \
    --d_model 256 \
    --num_layers 4 \
    --num_heads 4 \
    --d_ff 1024
```

### Thá»­ nghiá»‡m vá»›i beam search khÃ¡c nhau

```bash
# Greedy (beam_size=1)
python General_Domain/evaluate_general.py --beam_size 1

# Beam search (beam_size=5)
python General_Domain/evaluate_general.py --beam_size 5
```

## ğŸ“š TÃ i liá»‡u tham kháº£o

- **Full Documentation**: Xem `README.md`
- **Module Documentation**: Má»—i file Python cÃ³ docstrings chi tiáº¿t
- **Config Examples**: Xem `configs/` folder
- **Demo Code**: `demo_inference.py`

## ğŸ’¡ Tips & Tricks

### TÄƒng tá»‘c Training

1. **Pre-extract region features**: Cháº¡y Faster R-CNN má»™t láº§n, lÆ°u features vÃ o HDF5
2. **Mixed Precision Training**: Sá»­ dá»¥ng `torch.cuda.amp`
3. **Gradient Accumulation**: TÄƒng effective batch size
4. **Multi-GPU Training**: Sá»­ dá»¥ng `DistributedDataParallel`

### Cáº£i thiá»‡n Performance

1. **Data Augmentation**: ThÃªm random crops, flips
2. **Curriculum Learning**: Train trÃªn captions ngáº¯n trÆ°á»›c
3. **Ensemble**: Káº¿t há»£p nhiá»u models
4. **Post-processing**: Spell checking, grammar correction

### Debug

```bash
# Test vá»›i subset nhá»
head -n 1000 data.json > data_small.json

# In ra generated captions Ä‘á»‹nh ká»³
--log_every_n_steps 10

# Visualize attention weights
--visualize_attention True
```

## âœ… Checklist

- [ ] Environment setup hoÃ n táº¥t
- [ ] Data downloaded vÃ  preprocessed
- [ ] XE training completed (Phase 1)
- [ ] RL training completed (Phase 2)
- [ ] Evaluation cháº¡y thÃ nh cÃ´ng
- [ ] Metrics Ä‘áº¡t baseline
- [ ] Demo inference hoáº¡t Ä‘á»™ng
- [ ] Documentation Ä‘á»c vÃ  hiá»ƒu

## ğŸ†˜ Há»— trá»£

Náº¿u gáº·p váº¥n Ä‘á»:

1. Kiá»ƒm tra láº¡i requirements
2. Xem logs trong `./logs/`
3. Äá»c error messages cáº©n tháº­n
4. Táº¡o issue vá»›i thÃ´ng tin chi tiáº¿t:
   - Python version
   - CUDA version
   - Error traceback
   - Config sá»­ dá»¥ng

Good luck! ğŸš€
