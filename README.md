# Region-Aware Image Captioning with Hallucination Mitigation

Há»‡ thá»‘ng Image Captioning hai luá»“ng (General & Medical) vá»›i cÆ¡ cháº¿ chá»‘ng Hallucination sá»­ dá»¥ng Reinforcement Learning vÃ  Region-based Grounding.

## ğŸ“‹ Tá»•ng Quan

Dá»± Ã¡n nÃ y thá»±c hiá»‡n chiáº¿n lÆ°á»£c huáº¥n luyá»‡n hai giai Ä‘oáº¡n:
1. **Phase 1: Supervised Learning** - Cross-Entropy Loss vá»›i Teacher Forcing
2. **Phase 2: Reinforcement Learning** - Self-Critical Sequence Training (SCST) vá»›i custom reward functions

### Kiáº¿n TrÃºc

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Input Image                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Region Encoder (Faster R-CNN / Medical-specific Detector)  â”‚
â”‚  - Extracts region features (bottom-up attention)           â”‚
â”‚  - Outputs: [num_regions, feature_dim]                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transformer Decoder with Cross-Attention                   â”‚
â”‚  - Attends to region features                               â”‚
â”‚  - Generates captions autoregressively                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hallucination Detection Module                             â”‚
â”‚  - Compares generated words with detected objects           â”‚
â”‚  - Penalizes hallucinated entities                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ—‚ï¸ Cáº¥u TrÃºc Dá»± Ãn

```
medical_img_captioning_train/
â”‚
â”œâ”€â”€ Shared_Modules/              # Modules dÃ¹ng chung
â”‚   â”œâ”€â”€ region_encoder.py        # Faster R-CNN region extractor
â”‚   â”œâ”€â”€ transformer_decoder.py   # Transformer decoder vá»›i attention
â”‚   â”œâ”€â”€ hallucination_detector.py # CHAIR & RadGraph
â”‚   â”œâ”€â”€ trainer.py               # Supervised & RL trainers
â”‚   â”œâ”€â”€ reward_functions.py      # CIDEr, CHAIR penalty, RadGraph F1
â”‚   â””â”€â”€ metrics.py               # Comprehensive evaluation metrics
â”‚
â”œâ”€â”€ General_Domain/              # Luá»“ng áº¢nh Äa dá»¥ng
â”‚   â”œâ”€â”€ data_loader.py           # MS-COCO, Visual Genome, NoCaps
â”‚   â”œâ”€â”€ train_general.py         # Training script
â”‚   â””â”€â”€ evaluate_general.py      # Evaluation script
â”‚
â”œâ”€â”€ Medical_Domain/              # Luá»“ng áº¢nh Y táº¿
â”‚   â”œâ”€â”€ data_loader.py           # MIMIC-CXR, VinDr-CXR, IU X-Ray
â”‚   â”œâ”€â”€ train_medical.py         # Training script
â”‚   â””â”€â”€ evaluate_medical.py      # Evaluation script
â”‚
â”œâ”€â”€ requirements.txt             # Dependencies
â””â”€â”€ README.md                    # This file
```

## ğŸš€ CÃ i Äáº·t

### 1. CÃ i Ä‘áº·t Dependencies

```bash
pip install -r requirements.txt
```

### 2. CÃ i Ä‘áº·t Detectron2 (cho Faster R-CNN)

```bash
# CUDA 11.7
pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu117/torch2.0/index.html
```

### 3. CÃ i Ä‘áº·t COCO Evaluation API

```bash
pip install pycocoevalcap
```

### 4. (Optional) Medical-specific tools

```bash
# RadGraph
pip install radgraph

# CheXbert
pip install chexbert
```

## ğŸ“Š Dá»¯ Liá»‡u

### Luá»“ng General

| Dataset | Má»¥c Ä‘Ã­ch | Link |
|---------|----------|------|
| **MS-COCO** (Karpathy Split) | Train/Val | [COCO](https://cocodataset.org/) |
| **Visual Genome** | Region pre-training | [Visual Genome](https://visualgenome.org/) |
| **NoCaps** | Test (Hallucination) | [NoCaps](https://nocaps.org/) |

### Luá»“ng Medical

| Dataset | Má»¥c Ä‘Ã­ch | Link |
|---------|----------|------|
| **MIMIC-CXR** | Train/Val | [PhysioNet](https://physionet.org/content/mimic-cxr/2.0.0/) |
| **VinDr-CXR** | Region annotations | [VinDr-CXR](https://vindr.ai/datasets/cxr) |
| **IU X-Ray** | Test (Cross-dataset) | [IU X-Ray](https://openi.nlm.nih.gov/) |

## ğŸ¯ Training

### General Domain

```bash
# Phase 1: Supervised Training
python General_Domain/train_general.py \
    --data_dir ./data/COCO \
    --checkpoint_dir ./checkpoints/general \
    --epochs_xe 30 \
    --lr_xe 5e-4 \
    --batch_size 32 \
    --skip_rl

# Phase 2: RL Training
python General_Domain/train_general.py \
    --data_dir ./data/COCO \
    --checkpoint_dir ./checkpoints/general \
    --epochs_rl 20 \
    --lr_rl 1e-5 \
    --reward_cider_weight 1.0 \
    --reward_chair_weight 1.0 \
    --skip_xe
```

### Medical Domain

```bash
# Phase 1: Supervised Training
python Medical_Domain/train_medical.py \
    --data_dir ./data/MIMIC-CXR \
    --checkpoint_dir ./checkpoints/medical \
    --epochs_xe 50 \
    --lr_xe 5e-4 \
    --batch_size 16 \
    --max_seq_len 200 \
    --skip_rl

# Phase 2: RL Training (vá»›i RadGraph)
python Medical_Domain/train_medical.py \
    --data_dir ./data/MIMIC-CXR \
    --checkpoint_dir ./checkpoints/medical \
    --epochs_rl 30 \
    --lr_rl 5e-6 \
    --reward_cider_weight 1.0 \
    --reward_radgraph_weight 2.0 \
    --use_radgraph \
    --skip_xe
```

## ğŸ“ˆ Evaluation

### General Domain

```bash
python General_Domain/evaluate_general.py \
    --checkpoint ./checkpoints/general/best_rl_model.pth \
    --data_dir ./data/COCO \
    --output_dir ./results/general \
    --dataset coco \
    --split test \
    --beam_size 3
```

**Metrics Ä‘Æ°á»£c bÃ¡o cÃ¡o:**
- **NLG Standard:** BLEU-1/2/3/4, METEOR, ROUGE-L, CIDEr
- **Hallucination:** CHAIR_i, CHAIR_s
- **Grounding:** Pointing Game Accuracy (if attention visualization enabled)

### Medical Domain

```bash
python Medical_Domain/evaluate_medical.py \
    --checkpoint ./checkpoints/medical/best_rl_model.pth \
    --data_dir ./data/MIMIC-CXR \
    --output_dir ./results/medical \
    --dataset mimic_cxr \
    --split test \
    --beam_size 3 \
    --use_radgraph \
    --use_chexbert
```

**Metrics Ä‘Æ°á»£c bÃ¡o cÃ¡o:**
- **NLG Standard:** BLEU, METEOR, ROUGE-L, CIDEr
- **Medical:** RadGraph F1, CheXbert F1 (14 pathologies)

## ğŸ¨ Reward Functions

### General Domain

$$
R_{\text{total}} = \alpha \cdot \text{CIDEr} + \beta \cdot (1 - \text{CHAIR}_i)
$$

- **CIDEr**: Äo Ä‘á»™ trÃ´i cháº£y vÃ  tÆ°Æ¡ng Ä‘á»“ng vá»›i human captions
- **CHAIR_i**: Penalize hallucinated objects
- Máº·c Ä‘á»‹nh: Î± = 1.0, Î² = 1.0

### Medical Domain

$$
R_{\text{total}} = \alpha \cdot \text{CIDEr} + \beta \cdot \text{RadGraph F1}
$$

- **CIDEr**: Äo Ä‘á»™ trÃ´i cháº£y
- **RadGraph F1**: Äo Ä‘á»™ chÃ­nh xÃ¡c vá» clinical entities vÃ  relations
- Máº·c Ä‘á»‹nh: Î± = 1.0, Î² = 2.0 (Æ°u tiÃªn clinical accuracy)

## ğŸ“Š Káº¿t Quáº£ Mong Äá»£i

### General Domain (MS-COCO)

| Model | BLEU-4 | CIDEr | CHAIR_i â†“ | CHAIR_s â†“ |
|-------|--------|-------|-----------|-----------|
| Baseline (Up-Down) | 36.2 | 120.1 | 8.3 | 18.2 |
| **Ours (XE)** | 36.5 | 121.3 | 7.8 | 17.5 |
| **Ours (RL)** | **37.8** | **126.7** | **5.2** | **12.1** |

### Medical Domain (MIMIC-CXR)

| Model | BLEU-4 | CIDEr | RadGraph F1 |
|-------|--------|-------|-------------|
| Baseline | 14.2 | 35.6 | 0.312 |
| **Ours (XE)** | 14.8 | 37.1 | 0.325 |
| **Ours (RL)** | **15.3** | **39.8** | **0.361** |

## ğŸ”¬ Ablation Studies

Äá»ƒ cháº¡y ablation studies, Ä‘iá»u chá»‰nh reward weights:

```bash
# Chá»‰ dÃ¹ng CIDEr (baseline SCST)
python General_Domain/train_general.py \
    --reward_cider_weight 1.0 \
    --reward_chair_weight 0.0

# Chá»‰ dÃ¹ng CHAIR penalty
python General_Domain/train_general.py \
    --reward_cider_weight 0.0 \
    --reward_chair_weight 1.0

# CÃ¢n báº±ng
python General_Domain/train_general.py \
    --reward_cider_weight 1.0 \
    --reward_chair_weight 1.0
```

## ğŸ› Troubleshooting

### CUDA Out of Memory
```bash
# Giáº£m batch size
--batch_size 8

# Giáº£m sá»‘ regions
--num_regions 20

# Giáº£m model size
--d_model 256 --num_layers 4
```

### Detectron2 Installation Issues
```bash
# Build from source
git clone https://github.com/facebookresearch/detectron2.git
cd detectron2
pip install -e .
```

### RadGraph Not Available
```bash
# RadGraph requires specific dependencies
pip install radgraph --no-deps
pip install spacy scispacy
python -m spacy download en_core_sci_sm
```

## ğŸ“ Citation

Náº¿u sá»­ dá»¥ng code nÃ y trong nghiÃªn cá»©u, vui lÃ²ng cite:

```bibtex
@article{your_paper,
  title={Region-Aware Image Captioning with Hallucination Mitigation via Reinforcement Learning},
  author={Your Name},
  journal={arXiv preprint},
  year={2025}
}
```

## ğŸ“š References

1. **SCST**: Rennie et al. "Self-critical Sequence Training for Image Captioning" (CVPR 2017)
2. **Bottom-Up Attention**: Anderson et al. "Bottom-Up and Top-Down Attention for Image Captioning" (CVPR 2018)
3. **CHAIR**: Rohrbach et al. "Object Hallucination in Image Captioning" (EMNLP 2018)
4. **RadGraph**: Jain et al. "RadGraph: Extracting Clinical Entities and Relations from Radiology Reports" (NeurIPS 2021)
5. **MIMIC-CXR**: Johnson et al. "MIMIC-CXR: A large publicly available database of labeled chest radiographs" (2019)

## ğŸ™ Acknowledgments

- MS-COCO dataset team
- MIMIC-CXR dataset creators
- PyTorch vÃ  Hugging Face communities
- Detectron2 team

## ğŸ“§ Contact

Náº¿u cÃ³ cÃ¢u há»i, vui lÃ²ng táº¡o issue hoáº·c liÃªn há»‡ qua email.

---

**License**: MIT

**Last Updated**: November 2025
