{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eac6ffa",
   "metadata": {
    "papermill": {
     "duration": 0.016272,
     "end_time": "2023-07-18T09:38:34.149990",
     "exception": false,
     "start_time": "2023-07-18T09:38:34.133718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae008d84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:38:34.182782Z",
     "iopub.status.busy": "2023-07-18T09:38:34.182377Z",
     "iopub.status.idle": "2023-07-18T09:38:46.693972Z",
     "shell.execute_reply": "2023-07-18T09:38:46.692665Z"
    },
    "papermill": {
     "duration": 12.53074,
     "end_time": "2023-07-18T09:38:46.696502",
     "exception": false,
     "start_time": "2023-07-18T09:38:34.165762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17900903",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:38:46.719656Z",
     "iopub.status.busy": "2023-07-18T09:38:46.717946Z",
     "iopub.status.idle": "2023-07-18T09:38:58.464707Z",
     "shell.execute_reply": "2023-07-18T09:38:58.463681Z"
    },
    "papermill": {
     "duration": 11.760247,
     "end_time": "2023-07-18T09:38:58.467079",
     "exception": false,
     "start_time": "2023-07-18T09:38:46.706832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f23ced6",
   "metadata": {
    "papermill": {
     "duration": 0.009745,
     "end_time": "2023-07-18T09:38:58.487189",
     "exception": false,
     "start_time": "2023-07-18T09:38:58.477444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Defining Data Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2237b1f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:38:58.508763Z",
     "iopub.status.busy": "2023-07-18T09:38:58.508120Z",
     "iopub.status.idle": "2023-07-18T09:38:58.514844Z",
     "shell.execute_reply": "2023-07-18T09:38:58.514014Z"
    },
    "papermill": {
     "duration": 0.01954,
     "end_time": "2023-07-18T09:38:58.516799",
     "exception": false,
     "start_time": "2023-07-18T09:38:58.497259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainval_image_dir = os.path.join('/kaggle/input/coco-image-caption', 'train2014', 'train2014')\n",
    "trainval_captions_dir = os.path.join('/kaggle/input/coco-image-caption', 'annotations_trainval2014', 'annotations')\n",
    "test_image_dir = os.path.join('/kaggle/input/coco-image-caption', 'val2017', 'val2017')\n",
    "test_captions_dir = os.path.join('/kaggle/input/coco-image-caption', 'annotations_trainval2017', 'annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b673ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:38:58.537410Z",
     "iopub.status.busy": "2023-07-18T09:38:58.537152Z",
     "iopub.status.idle": "2023-07-18T09:38:58.541809Z",
     "shell.execute_reply": "2023-07-18T09:38:58.540769Z"
    },
    "papermill": {
     "duration": 0.017244,
     "end_time": "2023-07-18T09:38:58.543820",
     "exception": false,
     "start_time": "2023-07-18T09:38:58.526576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainval_captions_filepath = os.path.join(trainval_captions_dir, 'captions_train2014.json')\n",
    "test_captions_filepath = os.path.join(test_captions_dir, 'captions_val2017.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf4a445",
   "metadata": {
    "papermill": {
     "duration": 0.009795,
     "end_time": "2023-07-18T09:38:58.563422",
     "exception": false,
     "start_time": "2023-07-18T09:38:58.553627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Splitting Data into Train and Validation Set\n",
    "\n",
    "We'll be using 20% of train_2014 data to be used as our Validation Set and rest as Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefc53a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:38:58.584446Z",
     "iopub.status.busy": "2023-07-18T09:38:58.584186Z",
     "iopub.status.idle": "2023-07-18T09:38:59.565209Z",
     "shell.execute_reply": "2023-07-18T09:38:59.564238Z"
    },
    "papermill": {
     "duration": 0.994258,
     "end_time": "2023-07-18T09:38:59.567729",
     "exception": false,
     "start_time": "2023-07-18T09:38:58.573471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_filepaths = np.array([os.path.join(trainval_image_dir, f) for f in os.listdir(trainval_image_dir)])\n",
    "rand_indices = np.arange(len(all_filepaths))\n",
    "np.random.shuffle(rand_indices)\n",
    "\n",
    "split = int(len(all_filepaths)*0.8)\n",
    "\n",
    "train_filepaths, valid_filepaths = all_filepaths[rand_indices[:split]], all_filepaths[rand_indices[split:]] \n",
    "\n",
    "print(f\"Train dataset size: {len(train_filepaths)}\")\n",
    "print(f\"Valid dataset size: {len(valid_filepaths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11db3d88",
   "metadata": {
    "papermill": {
     "duration": 0.009958,
     "end_time": "2023-07-18T09:38:59.588060",
     "exception": false,
     "start_time": "2023-07-18T09:38:59.578102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Processing Data\n",
    "\n",
    "Here we'll be making train, valid and test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a4780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:38:59.609888Z",
     "iopub.status.busy": "2023-07-18T09:38:59.609004Z",
     "iopub.status.idle": "2023-07-18T09:39:07.652297Z",
     "shell.execute_reply": "2023-07-18T09:39:07.651128Z"
    },
    "papermill": {
     "duration": 8.057063,
     "end_time": "2023-07-18T09:39:07.655268",
     "exception": false,
     "start_time": "2023-07-18T09:38:59.598205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(trainval_captions_filepath, 'r') as f:\n",
    "    trainval_data = json.load(f)\n",
    "    \n",
    "trainval_captions_df = pd.json_normalize(trainval_data, \"annotations\")\n",
    "trainval_captions_df[\"image_filepath\"] = trainval_captions_df[\"image_id\"].apply(\n",
    "    lambda x: os.path.join(trainval_image_dir, 'COCO_train2014_'+format(x, '012d')+'.jpg')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d5aa71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:39:07.678598Z",
     "iopub.status.busy": "2023-07-18T09:39:07.677608Z",
     "iopub.status.idle": "2023-07-18T09:39:09.449948Z",
     "shell.execute_reply": "2023-07-18T09:39:09.448926Z"
    },
    "papermill": {
     "duration": 1.786479,
     "end_time": "2023-07-18T09:39:09.452467",
     "exception": false,
     "start_time": "2023-07-18T09:39:07.665988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_captions(image_captions_df):\n",
    "    \"\"\" Preprocessing the captions \"\"\"\n",
    "    \n",
    "    image_captions_df[\"preprocessed_caption\"] = \"[START] \" + image_captions_df[\"caption\"].str.lower().str.replace('[^\\w\\s]','') + \" [END]\"\n",
    "    return image_captions_df\n",
    "\n",
    "train_captions_df = trainval_captions_df[trainval_captions_df[\"image_filepath\"].isin(train_filepaths)]\n",
    "train_captions_df = preprocess_captions(train_captions_df)\n",
    "valid_captions_df = trainval_captions_df[trainval_captions_df[\"image_filepath\"].isin(valid_filepaths)]\n",
    "valid_captions_df = preprocess_captions(valid_captions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea3d6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:39:09.476597Z",
     "iopub.status.busy": "2023-07-18T09:39:09.476272Z",
     "iopub.status.idle": "2023-07-18T09:39:10.039532Z",
     "shell.execute_reply": "2023-07-18T09:39:10.038468Z"
    },
    "papermill": {
     "duration": 0.577314,
     "end_time": "2023-07-18T09:39:10.041738",
     "exception": false,
     "start_time": "2023-07-18T09:39:09.464424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(test_captions_filepath, 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "    \n",
    "test_captions_df = pd.json_normalize(test_data, \"annotations\")\n",
    "test_captions_df[\"image_filepath\"] = test_captions_df[\"image_id\"].apply(\n",
    "    lambda x: os.path.join(test_image_dir, format(x, '012d')+'.jpg')\n",
    ")\n",
    "test_captions_df = preprocess_captions(test_captions_df)\n",
    "\n",
    "train_captions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c563dd7b",
   "metadata": {
    "papermill": {
     "duration": 0.010932,
     "end_time": "2023-07-18T09:39:10.063402",
     "exception": false,
     "start_time": "2023-07-18T09:39:10.052470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adcc651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:39:10.090305Z",
     "iopub.status.busy": "2023-07-18T09:39:10.089993Z",
     "iopub.status.idle": "2023-07-18T09:39:11.349857Z",
     "shell.execute_reply": "2023-07-18T09:39:11.347599Z"
    },
    "papermill": {
     "duration": 1.281929,
     "end_time": "2023-07-18T09:39:11.359727",
     "exception": false,
     "start_time": "2023-07-18T09:39:10.077798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_data = test_captions_df.groupby(\"image_filepath\")[\"caption\"].agg(list).iloc[:5]\n",
    "\n",
    "fig, axes = plt.subplots(5, 2, figsize=(8,18))\n",
    "\n",
    "for ax_row, index, sample in zip(axes, sample_data.index, sample_data):\n",
    "    \n",
    "    ax_row[0].imshow(Image.open(index))\n",
    "    ax_row[0].axis(\"off\")\n",
    "    text_y = 0.9\n",
    "    for cap in sample:\n",
    "        ax_row[1].text(0, text_y, cap, fontsize=14)\n",
    "        text_y -= 0.2\n",
    "    ax_row[1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf29263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:39:11.404038Z",
     "iopub.status.busy": "2023-07-18T09:39:11.403688Z",
     "iopub.status.idle": "2023-07-18T09:39:12.851555Z",
     "shell.execute_reply": "2023-07-18T09:39:12.850561Z"
    },
    "papermill": {
     "duration": 1.473574,
     "end_time": "2023-07-18T09:39:12.853925",
     "exception": false,
     "start_time": "2023-07-18T09:39:11.380351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "\n",
    "train_image_stats_df = train_captions_df.loc[:n_samples, \"image_filepath\"].apply(lambda x: Image.open(x).size)\n",
    "train_image_stats_df = pd.DataFrame(train_image_stats_df.tolist(), index=train_image_stats_df.index)\n",
    "train_image_stats_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b00fdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:39:12.896791Z",
     "iopub.status.busy": "2023-07-18T09:39:12.896443Z",
     "iopub.status.idle": "2023-07-18T09:39:15.191695Z",
     "shell.execute_reply": "2023-07-18T09:39:15.190187Z"
    },
    "papermill": {
     "duration": 2.320149,
     "end_time": "2023-07-18T09:39:15.194617",
     "exception": false,
     "start_time": "2023-07-18T09:39:12.874468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_vocabulary = train_captions_df[\"preprocessed_caption\"].str.split(\" \").explode().value_counts()\n",
    "print(len(train_vocabulary[train_vocabulary>=25]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18a5ea3",
   "metadata": {
    "papermill": {
     "duration": 0.020109,
     "end_time": "2023-07-18T09:39:15.235271",
     "exception": false,
     "start_time": "2023-07-18T09:39:15.215162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Understanding the Bert Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e273a4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:39:15.277459Z",
     "iopub.status.busy": "2023-07-18T09:39:15.277155Z",
     "iopub.status.idle": "2023-07-18T09:39:22.244999Z",
     "shell.execute_reply": "2023-07-18T09:39:22.243727Z"
    },
    "papermill": {
     "duration": 6.991814,
     "end_time": "2023-07-18T09:39:22.247239",
     "exception": false,
     "start_time": "2023-07-18T09:39:15.255425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "\n",
    "# Initialize an empty BERT tokenizer\n",
    "tokenizer = BertWordPieceTokenizer(\n",
    "    #reserved_tokens=[\"[UNK]\", \"[START]\", \"[END]\", \"[PAD]\"],\n",
    "    unk_token=\"[UNK]\",\n",
    "    #trainer_params=None,\n",
    "    #vocab_size=8000,\n",
    "    clean_text=False,\n",
    "    lowercase=False,\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(\n",
    "    train_captions_df[\"preprocessed_caption\"].tolist(),\n",
    "    vocab_size=4000,\n",
    "    special_tokens=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06576e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:39:22.291362Z",
     "iopub.status.busy": "2023-07-18T09:39:22.291030Z",
     "iopub.status.idle": "2023-07-18T09:39:22.299108Z",
     "shell.execute_reply": "2023-07-18T09:39:22.297584Z"
    },
    "papermill": {
     "duration": 0.032787,
     "end_time": "2023-07-18T09:39:22.301107",
     "exception": false,
     "start_time": "2023-07-18T09:39:22.268320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encoding a sentence\n",
    "example_captions = valid_captions_df[\"preprocessed_caption\"].iloc[:10].tolist()\n",
    "example_tokenized_captions = tokenizer.encode_batch(example_captions)\n",
    "\n",
    "for caption, tokenized_cap in zip(example_captions, example_tokenized_captions):\n",
    "    print(f\"{caption} -> {tokenized_cap.tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3c0c5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:39:22.343716Z",
     "iopub.status.busy": "2023-07-18T09:39:22.342836Z",
     "iopub.status.idle": "2023-07-18T09:39:22.351425Z",
     "shell.execute_reply": "2023-07-18T09:39:22.350552Z"
    },
    "papermill": {
     "duration": 0.032286,
     "end_time": "2023-07-18T09:39:22.353570",
     "exception": false,
     "start_time": "2023-07-18T09:39:22.321284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "for token in [\"[UNK]\", \"[PAD]\", \"[START]\", \"[END]\"]:\n",
    "    print(f\"{token} -> {vocab[token]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017b4d08",
   "metadata": {
    "papermill": {
     "duration": 0.019947,
     "end_time": "2023-07-18T09:39:22.393400",
     "exception": false,
     "start_time": "2023-07-18T09:39:22.373453",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Defining the `tf.data.Dataset` for image captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe906f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:39:22.435074Z",
     "iopub.status.busy": "2023-07-18T09:39:22.434791Z",
     "iopub.status.idle": "2023-07-18T09:39:22.440419Z",
     "shell.execute_reply": "2023-07-18T09:39:22.439397Z"
    },
    "papermill": {
     "duration": 0.029328,
     "end_time": "2023-07-18T09:39:22.442640",
     "exception": false,
     "start_time": "2023-07-18T09:39:22.413312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_image(filepath, resize_height, resize_width):\n",
    "    image = tf.io.read_file(filepath)\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [resize_height, resize_width])\n",
    "    image = image*2.0 - 1.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b9e42a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:39:22.484692Z",
     "iopub.status.busy": "2023-07-18T09:39:22.483952Z",
     "iopub.status.idle": "2023-07-18T09:39:22.489532Z",
     "shell.execute_reply": "2023-07-18T09:39:22.488580Z"
    },
    "papermill": {
     "duration": 0.02925,
     "end_time": "2023-07-18T09:39:22.491489",
     "exception": false,
     "start_time": "2023-07-18T09:39:22.462239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_tokenizer(captions_df, n_vocab):\n",
    "    \"\"\" Generate the tokenizer with given captions \"\"\"\n",
    "    \n",
    "    # Define the tokenizer\n",
    "    tokenizer = BertWordPieceTokenizer(\n",
    "        unk_token=\"[UNK]\",\n",
    "        clean_text=False,\n",
    "        lowercase=False,\n",
    "    )\n",
    "    \n",
    "    # Train the tokenizer\n",
    "    tokenizer.train_from_iterator(\n",
    "        captions_df[\"preprocessed_caption\"].tolist(),\n",
    "        vocab_size=n_vocab,\n",
    "        special_tokens=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n",
    "    )\n",
    "    \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f2c238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:39:22.534381Z",
     "iopub.status.busy": "2023-07-18T09:39:22.533528Z",
     "iopub.status.idle": "2023-07-18T09:39:22.543655Z",
     "shell.execute_reply": "2023-07-18T09:39:22.542644Z"
    },
    "papermill": {
     "duration": 0.034536,
     "end_time": "2023-07-18T09:39:22.545779",
     "exception": false,
     "start_time": "2023-07-18T09:39:22.511243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_tf_dataset(image_captions_df, tokenizer=None, n_vocab=5000, pad_length=33, batch_size=32, training=False):\n",
    "    \"\"\" Generate the tf.data.Dataset\"\"\"\n",
    "    \n",
    "    # If the tokenizer is not available, create one\n",
    "    if not tokenizer:\n",
    "        tokenizer = generate_tokenizer(image_captions_df, n_vocab)\n",
    "        \n",
    "    # Get the caption IDs using the tokenizer\n",
    "    image_captions_df[\"caption_token_ids\"] = [enc.ids for enc in tokenizer.encode_batch(image_captions_df[\"preprocessed_caption\"])]\n",
    "    \n",
    "    vocab = tokenizer.get_vocab()\n",
    "    \n",
    "    # Add the padding to short sentences and truncate long ones\n",
    "    image_captions_df[\"caption_token_ids\"] = image_captions_df[\"caption_token_ids\"].apply(\n",
    "        lambda x: x+[vocab[\"[PAD]\"]]*(pad_length - len(x) + 2) if pad_length + 2 >= len(x) else x[:pad_length + 1] + [x[-1]]\n",
    "    ) \n",
    "    \n",
    "    # Create a dataset with images and captions\n",
    "    dataset = tf.data.Dataset.from_tensor_slices({\n",
    "        \"image_filepath\": image_captions_df[\"image_filepath\"],\n",
    "        \"caption_token_ids\": np.array(image_captions_df[\"caption_token_ids\"].tolist())\n",
    "    })\n",
    "    \n",
    "    # Each sample in our dataset consists of\n",
    "    # (image, caption token IDs, position IDs), (caption token IDs offset by 1)\n",
    "    dataset = dataset.map(\n",
    "        lambda x: (\n",
    "            (parse_image(x[\"image_filepath\"], 224, 224), x[\"caption_token_ids\"][:-1], tf.range(pad_length+1, dtype='float32')), x[\"caption_token_ids\"]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Shuffle and batch data in the training mode\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(buffer_size=batch_size*10)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c48f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:39:22.589497Z",
     "iopub.status.busy": "2023-07-18T09:39:22.588032Z",
     "iopub.status.idle": "2023-07-18T09:39:46.490567Z",
     "shell.execute_reply": "2023-07-18T09:39:46.487240Z"
    },
    "papermill": {
     "duration": 23.927248,
     "end_time": "2023-07-18T09:39:46.492973",
     "exception": false,
     "start_time": "2023-07-18T09:39:22.565725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_vocab=4000\n",
    "batch_size=2\n",
    "sample_dataset, sample_tokenizer = generate_tf_dataset(train_captions_df, n_vocab=n_vocab, pad_length=10, batch_size=batch_size, training=True)\n",
    "for i in sample_dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be261c47",
   "metadata": {
    "papermill": {
     "duration": 0.020528,
     "end_time": "2023-07-18T09:39:46.535515",
     "exception": false,
     "start_time": "2023-07-18T09:39:46.514987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Defining the model\n",
    "\n",
    "Our model consists of,\n",
    "\n",
    "* A Vision Transformer(ViT) - Takes in patches of images as inputs and produce a sequence of output representations for each patch\n",
    "* A Text Decoder Transformer - Takes in the final representation of the vision Transformer, along with input caption IDs and predict the next token in the caption for each time step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9734fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:39:46.578664Z",
     "iopub.status.busy": "2023-07-18T09:39:46.578330Z",
     "iopub.status.idle": "2023-07-18T09:39:56.813109Z",
     "shell.execute_reply": "2023-07-18T09:39:56.811577Z"
    },
    "papermill": {
     "duration": 10.259226,
     "end_time": "2023-07-18T09:39:56.815267",
     "exception": false,
     "start_time": "2023-07-18T09:39:46.556041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "image_input = tf.keras.layers.Input(shape=(224, 224, 3))\n",
    "image_encoder = hub.KerasLayer(\"https://tfhub.dev/sayakpaul/vit_s16_fe/1\", trainable=False)\n",
    "image_features = image_encoder(image_input)\n",
    "print(f\"Final representation shape: {image_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48d8bce",
   "metadata": {
    "papermill": {
     "duration": 0.020699,
     "end_time": "2023-07-18T09:39:56.857531",
     "exception": false,
     "start_time": "2023-07-18T09:39:56.836832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The Text Decoder Transformer\n",
    "\n",
    "Here we define the text decoder. It takes the final image representation of ViT and concatenate that with caption IDs. Then we predict caption token ID from the next time step with the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5c9696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:39:56.903318Z",
     "iopub.status.busy": "2023-07-18T09:39:56.902946Z",
     "iopub.status.idle": "2023-07-18T09:40:05.466358Z",
     "shell.execute_reply": "2023-07-18T09:40:05.465127Z"
    },
    "papermill": {
     "duration": 8.592407,
     "end_time": "2023-07-18T09:40:05.470692",
     "exception": false,
     "start_time": "2023-07-18T09:39:56.878285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SelfAttentionLayer(tf.keras.layers.Layer):\n",
    "    \"\"\" Defines the computations in the self attention layer \"\"\"\n",
    "    \n",
    "    def __init__(self, d):        \n",
    "        super(SelfAttentionLayer, self).__init__()\n",
    "        # Feature dimensionality of the output\n",
    "        self.d = d\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # Query weight matrix\n",
    "        self.Wq = self.add_weight(\n",
    "            shape=(input_shape[-1], self.d), initializer='glorot_uniform',\n",
    "            trainable=True, dtype='float32'\n",
    "        )        \n",
    "        # Key weight matrix\n",
    "        self.Wk = self.add_weight(\n",
    "            shape=(input_shape[-1], self.d), initializer='glorot_uniform',\n",
    "            trainable=True, dtype='float32'\n",
    "        )\n",
    "        # Value weight matrix\n",
    "        self.Wv = self.add_weight(\n",
    "            shape=(input_shape[-1], self.d), initializer='glorot_uniform',\n",
    "            trainable=True, dtype='float32'\n",
    "        )\n",
    "    \n",
    "    def call(self, q_x, k_x, v_x, mask=None):\n",
    "        \n",
    "        q = tf.matmul(q_x,self.Wq) #[None, t, d]\n",
    "        k = tf.matmul(k_x,self.Wk) #[None, t, d]\n",
    "        v = tf.matmul(v_x,self.Wv) #[None, t, d]\n",
    "        \n",
    "        # Computing the final output\n",
    "        h = tf.keras.layers.Attention(causal=True)([\n",
    "            q, #q\n",
    "            v, #v\n",
    "            k, #k\n",
    "        ], mask=[None, mask]) # [None, t, t] . [None, t, d] => [None, t, d]\n",
    "        \n",
    "        return h\n",
    "    \n",
    "    \n",
    "class TransformerDecoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\" The Decoder layer \"\"\"\n",
    "    \n",
    "    def __init__(self, d, n_heads):\n",
    "        super(TransformerDecoderLayer, self).__init__()\n",
    "        # Feature dimensionality\n",
    "        self.d = d\n",
    "        \n",
    "        # Dimensionality of a head\n",
    "        self.d_head = int(d/n_heads) \n",
    "        \n",
    "        # Number of heads\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        # Actual attention heads\n",
    "        self.attn_heads = [SelfAttentionLayer(self.d_head) for i in range(self.n_heads)]\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1_layer = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.fc2_layer = tf.keras.layers.Dense(d)\n",
    "        \n",
    "        self.add_layer = tf.keras.layers.Add()\n",
    "        self.norm1_layer = tf.keras.layers.LayerNormalization()\n",
    "        self.norm2_layer = tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "    \n",
    "    def _compute_multihead_output(self, x):\n",
    "        \"\"\" Computing the multi head attention output\"\"\"\n",
    "        outputs = [head(x, x, x) for head in self.attn_heads]            \n",
    "        outputs = tf.concat(outputs, axis=-1)\n",
    "        return outputs\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        \n",
    "        # Multi head attention layer output\n",
    "        h1 = self._compute_multihead_output(x)\n",
    "        \n",
    "        h1_add = self.add_layer([x, h1])\n",
    "        h1_norm = self.norm1_layer(h1_add)\n",
    "        \n",
    "        # Fully connected outputs\n",
    "        h2_1 = self.fc1_layer(h1_norm)\n",
    "        h2_2 = self.fc2_layer(h2_1)\n",
    "        \n",
    "        h2_add = self.add_layer([h1, h2_2])\n",
    "        h2_norm = self.norm2_layer(h2_add)\n",
    "        \n",
    "        \n",
    "        return h2_norm\n",
    "    \n",
    "\n",
    "# Input layer\n",
    "caption_input = tf.keras.layers.Input(shape=(None,))\n",
    "position_input = tf.keras.layers.Input(shape=(None,))\n",
    "d_model = 384\n",
    "\n",
    "# Token embeddings\n",
    "input_embedding = tf.keras.layers.Embedding(len(tokenizer.get_vocab()), d_model, mask_zero=True)\n",
    "\n",
    "# Position embeddings\n",
    "position_embedding = tf.keras.layers.Lambda(\n",
    "    lambda x: tf.where(\n",
    "        tf.math.mod(tf.repeat(tf.expand_dims(x, axis=-1), d_model, axis=-1), 2)==0,\n",
    "        tf.math.sin(\n",
    "            #tf.repeat(tf.expand_dims(x, axis=-1), d_model, axis=-1) /\n",
    "            tf.expand_dims(x, axis=-1) /\n",
    "            10000**(2*tf.reshape(tf.range(d_model, dtype='float32'),[1,1, -1])/d_model)\n",
    "        ),\n",
    "        tf.math.cos(\n",
    "            tf.expand_dims(x, axis=-1) /\n",
    "            10000**(2*tf.reshape(tf.range(d_model, dtype='float32'),[1,1, -1])/d_model)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combined token position embeddings\n",
    "embed_out = input_embedding(caption_input) + position_embedding(position_input)\n",
    "# Concatenate image caption and token embeddings\n",
    "image_caption_embed_out = tf.keras.layers.Concatenate(axis=1)([tf.expand_dims(image_features,axis=1), embed_out])\n",
    "\n",
    "# Generate hidden representation with Transformer decoder layer\n",
    "out = image_caption_embed_out\n",
    "for l in range(4):\n",
    "    out  = TransformerDecoderLayer(d_model, 64)(out)\n",
    "\n",
    "# Final prediction layer\n",
    "final_out = tf.keras.layers.Dense(n_vocab, activation='softmax')(out)\n",
    "\n",
    "# Define the final model and compile\n",
    "full_model = tf.keras.models.Model(inputs=[image_input, caption_input, position_input], outputs=final_out)\n",
    "full_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics='accuracy')\n",
    "\n",
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc668c31",
   "metadata": {
    "papermill": {
     "duration": 0.023822,
     "end_time": "2023-07-18T09:40:05.518538",
     "exception": false,
     "start_time": "2023-07-18T09:40:05.494716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining the Blue Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9117be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:40:05.568230Z",
     "iopub.status.busy": "2023-07-18T09:40:05.567902Z",
     "iopub.status.idle": "2023-07-18T09:40:05.583732Z",
     "shell.execute_reply": "2023-07-18T09:40:05.582852Z"
    },
    "papermill": {
     "duration": 0.04338,
     "end_time": "2023-07-18T09:40:05.585884",
     "exception": false,
     "start_time": "2023-07-18T09:40:05.542504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "\n",
    "\n",
    "def _get_ngrams(segment, max_order):\n",
    "    \"\"\"Extracts all n-grams upto a given maximum order from an input segment.\n",
    "\n",
    "      Args:\n",
    "        segment: text segment from which n-grams will be extracted.\n",
    "        max_order: maximum length in tokens of the n-grams returned by this\n",
    "            methods.\n",
    "\n",
    "      Returns:\n",
    "        The Counter containing all n-grams upto max_order in segment\n",
    "        with a count of how many times each n-gram occurred.\n",
    "    \"\"\"\n",
    "    ngram_counts = collections.Counter()\n",
    "    for order in range(1, max_order + 1):\n",
    "        for i in range(0, len(segment) - order + 1):\n",
    "            ngram = tuple(segment[i:i+order])\n",
    "            ngram_counts[ngram] += 1\n",
    "    return ngram_counts\n",
    "\n",
    "\n",
    "def compute_bleu(reference_corpus, translation_corpus, max_order=4,\n",
    "                 smooth=False):\n",
    "    \"\"\"Computes BLEU score of translated segments against one or more references.\n",
    "\n",
    "      Args:\n",
    "        reference_corpus: list of lists of references for each translation. Each\n",
    "            reference should be tokenized into a list of tokens.\n",
    "        translation_corpus: list of translations to score. Each translation\n",
    "            should be tokenized into a list of tokens.\n",
    "        max_order: Maximum n-gram order to use when computing BLEU score.\n",
    "        smooth: Whether or not to apply Lin et al. 2004 smoothing.\n",
    "\n",
    "      Returns:\n",
    "        3-Tuple with the BLEU score, n-gram precisions, geometric mean of n-gram\n",
    "        precisions and brevity penalty.\n",
    "    \"\"\"\n",
    "    matches_by_order = [0] * max_order\n",
    "    possible_matches_by_order = [0] * max_order\n",
    "    reference_length = 0\n",
    "    translation_length = 0\n",
    "    for (references, translation) in zip(reference_corpus,\n",
    "                                           translation_corpus):\n",
    "        reference_length += min(len(r) for r in references)\n",
    "        translation_length += len(translation)\n",
    "\n",
    "        merged_ref_ngram_counts = collections.Counter()\n",
    "        for reference in references:\n",
    "            merged_ref_ngram_counts |= _get_ngrams(reference, max_order)\n",
    "        translation_ngram_counts = _get_ngrams(translation, max_order)\n",
    "        overlap = translation_ngram_counts & merged_ref_ngram_counts\n",
    "        for ngram in overlap:\n",
    "            matches_by_order[len(ngram)-1] += overlap[ngram]\n",
    "        for order in range(1, max_order+1):\n",
    "            possible_matches = len(translation) - order + 1\n",
    "            if possible_matches > 0:\n",
    "                possible_matches_by_order[order-1] += possible_matches\n",
    "\n",
    "        precisions = [0] * max_order\n",
    "        for i in range(0, max_order):\n",
    "            if smooth:\n",
    "                   precisions[i] = ((matches_by_order[i] + 1.) /\n",
    "                           (possible_matches_by_order[i] + 1.))\n",
    "            else:\n",
    "                if possible_matches_by_order[i] > 0:\n",
    "                    precisions[i] = (float(matches_by_order[i]) /\n",
    "                             possible_matches_by_order[i])\n",
    "                else:\n",
    "                    precisions[i] = 0.0\n",
    "\n",
    "        if min(precisions) > 0:\n",
    "            p_log_sum = sum((1. / max_order) * math.log(p) for p in precisions)\n",
    "            geo_mean = math.exp(p_log_sum)\n",
    "        else:\n",
    "            geo_mean = 0\n",
    "\n",
    "        ratio = float(translation_length) / reference_length\n",
    "\n",
    "        if ratio > 1.0:\n",
    "            bp = 1.\n",
    "        else:\n",
    "            bp = math.exp(1 - 1. / ratio)\n",
    "\n",
    "        bleu = geo_mean * bp\n",
    "\n",
    "        return (bleu, precisions, bp, ratio, translation_length, reference_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d87f20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:40:05.637933Z",
     "iopub.status.busy": "2023-07-18T09:40:05.637170Z",
     "iopub.status.idle": "2023-07-18T09:40:05.651177Z",
     "shell.execute_reply": "2023-07-18T09:40:05.650335Z"
    },
    "papermill": {
     "duration": 0.042308,
     "end_time": "2023-07-18T09:40:05.653139",
     "exception": false,
     "start_time": "2023-07-18T09:40:05.610831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "\n",
    "class BLEUMetric(object):\n",
    "    \n",
    "    def __init__(self, tokenizer, name='bleu_metric', **kwargs):\n",
    "        \"\"\" Computes the BLEU score (Metric for machine translation) \"\"\"\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "      #self.vocab = vocabulary\n",
    "      #self.id_to_token_layer = StringLookup(vocabulary=self.vocab, num_oov_indices=0, oov_token='[UNKUNK]', invert=True)\n",
    "    \n",
    "    def calculate_bleu_from_predictions(self, real, pred):\n",
    "        \"\"\" Calculate the BLEU score for targets and predictions \"\"\"\n",
    "        \n",
    "        # Get the predicted token IDs\n",
    "        pred_argmax = tf.argmax(pred, axis=-1)  \n",
    "        \n",
    "        # Convert token IDs to words using the vocabulary and the StringLookup\n",
    "        pred_tokens = np.array([[self.tokenizer.id_to_token(pp) for pp in p] for p in pred_argmax])\n",
    "        real_tokens = tf.constant([[self.tokenizer.id_to_token(rr) for rr in r] for r in real])\n",
    "        \n",
    "        def clean_text(tokens):\n",
    "            \n",
    "            \"\"\" Clean padding and other tokens to only keep meaningful words \"\"\"\n",
    "            \n",
    "            # 3. Strip the string of any extra white spaces\n",
    "            translations_in_bytes = tf.strings.strip(\n",
    "                        # 2. Replace everything after the eos token with blank\n",
    "                        tf.strings.regex_replace(\n",
    "                            # 1. Join all the tokens to one string in each sequence\n",
    "                            tf.strings.join(\n",
    "                                tf.transpose(tokens), separator=' '\n",
    "                            ),\n",
    "                        \"\\[END\\].*\", \"\"),\n",
    "                   )\n",
    "            \n",
    "            # Decode the byte stream to a string\n",
    "            translations = np.char.decode( #\n",
    "                translations_in_bytes.numpy().astype(np.bytes_), encoding='utf-8'\n",
    "            )\n",
    "            \n",
    "            # If the string is empty, add a [UNK] token\n",
    "            # Otherwise get a Division by zero error\n",
    "            translations = [sent if len(sent)>0 else \"[UNK]\" for sent in translations ]\n",
    "            \n",
    "            # Split the sequences to individual tokens \n",
    "            translations = np.char.split(translations).tolist()\n",
    "            \n",
    "            return translations\n",
    "        \n",
    "        # Get the clean versions of the predictions and real seuqences\n",
    "        pred_tokens = clean_text(pred_tokens)\n",
    "        # We have to wrap each real sequence in a list to make use of a function to compute bleu\n",
    "        real_tokens = [[token_seq] for token_seq in clean_text(real_tokens)]\n",
    "\n",
    "        # The compute_bleu method accpets the translations and references in the following format\n",
    "        # tranlation - list of list of tokens\n",
    "        # references - list of list of list of tokens\n",
    "        bleu, precisions, bp, ratio, translation_length, reference_length = compute_bleu(real_tokens, pred_tokens, smooth=False)\n",
    "\n",
    "        return bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a0f14c",
   "metadata": {
    "papermill": {
     "duration": 0.023712,
     "end_time": "2023-07-18T09:40:05.701111",
     "exception": false,
     "start_time": "2023-07-18T09:40:05.677399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d3876",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T09:40:05.751159Z",
     "iopub.status.busy": "2023-07-18T09:40:05.750323Z",
     "iopub.status.idle": "2023-07-18T13:29:42.005185Z",
     "shell.execute_reply": "2023-07-18T13:29:42.000059Z"
    },
    "papermill": {
     "duration": 13777.197191,
     "end_time": "2023-07-18T13:29:42.922311",
     "exception": false,
     "start_time": "2023-07-18T09:40:05.725120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size=96\n",
    "\n",
    "train_fraction = 0.6\n",
    "valid_fraction = 0.2\n",
    "\n",
    "tokenizer = generate_tokenizer(\n",
    "    train_captions_df, n_vocab=n_vocab\n",
    ")\n",
    "\n",
    "bleu_metric = BLEUMetric(tokenizer=tokenizer)\n",
    "\n",
    "sampled_validation_captions_df = valid_captions_df.sample(frac=valid_fraction)\n",
    "\n",
    "for e in range(5):\n",
    "    print(f\"Epoch: {e+1}\")\n",
    "    \n",
    "    train_dataset, _ = generate_tf_dataset(\n",
    "        train_captions_df.sample(frac=train_fraction), tokenizer=tokenizer, n_vocab=n_vocab, batch_size=batch_size, training=True\n",
    "    )\n",
    "    valid_dataset, _ = generate_tf_dataset(\n",
    "        sampled_validation_captions_df, tokenizer=tokenizer, n_vocab=n_vocab, batch_size=batch_size, training=False\n",
    "    )\n",
    "    \n",
    "    full_model.fit(\n",
    "        train_dataset,\n",
    "        epochs=1\n",
    "    )\n",
    "    \n",
    "    valid_loss, valid_accuracy, valid_bleu = [], [], []\n",
    "    for vi, v_batch in enumerate(valid_dataset):\n",
    "        print(f\"{vi+1} batches processed\", end='\\r')\n",
    "        loss, accuracy = full_model.test_on_batch(v_batch[0], v_batch[1])\n",
    "        batch_predicted = full_model(v_batch[0])\n",
    "        bleu_score = bleu_metric.calculate_bleu_from_predictions(v_batch[1], batch_predicted)\n",
    "        valid_loss.append(loss)\n",
    "        valid_accuracy.append(accuracy)\n",
    "        valid_bleu.append(bleu_score)\n",
    "        \n",
    "    print(\n",
    "        f\"\\nvalid_loss: {np.mean(valid_loss)} - valid_accuracy: {np.mean(valid_accuracy)} - valid_bleu: {np.mean(valid_bleu)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c23b7",
   "metadata": {
    "papermill": {
     "duration": 0.967973,
     "end_time": "2023-07-18T13:29:44.780819",
     "exception": false,
     "start_time": "2023-07-18T13:29:43.812846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluating the Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246037e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T13:29:46.595441Z",
     "iopub.status.busy": "2023-07-18T13:29:46.594995Z",
     "iopub.status.idle": "2023-07-18T13:51:54.753235Z",
     "shell.execute_reply": "2023-07-18T13:51:54.752205Z"
    },
    "papermill": {
     "duration": 1329.983578,
     "end_time": "2023-07-18T13:51:55.659163",
     "exception": false,
     "start_time": "2023-07-18T13:29:45.675585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bleu_metric = BLEUMetric(tokenizer=tokenizer)\n",
    "\n",
    "test_dataset, _ = generate_tf_dataset(\n",
    "    test_captions_df, tokenizer=tokenizer, n_vocab=n_vocab, batch_size=batch_size, training=False\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy, test_bleu = [], [], []\n",
    "for ti, t_batch in enumerate(test_dataset):\n",
    "    print(f\"{ti+1} batches processed\", end='\\r')\n",
    "    loss, accuracy = full_model.test_on_batch(t_batch[0], t_batch[1])\n",
    "    batch_predicted = full_model.predict_on_batch(t_batch[0])\n",
    "    bleu_score = bleu_metric.calculate_bleu_from_predictions(t_batch[1], batch_predicted)\n",
    "    test_loss.append(loss)\n",
    "    test_accuracy.append(accuracy)\n",
    "    test_bleu.append(bleu_score)\n",
    "\n",
    "print(\n",
    "    f\"\\ntest_loss: {np.mean(test_loss)} - test_accuracy: {np.mean(test_accuracy)} - test_bleu: {np.mean(test_bleu)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcae175",
   "metadata": {
    "papermill": {
     "duration": 0.913937,
     "end_time": "2023-07-18T13:51:57.476408",
     "exception": false,
     "start_time": "2023-07-18T13:51:56.562471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generating image captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57749d66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T13:51:59.903840Z",
     "iopub.status.busy": "2023-07-18T13:51:59.902799Z",
     "iopub.status.idle": "2023-07-18T13:52:52.214058Z",
     "shell.execute_reply": "2023-07-18T13:52:52.213200Z"
    },
    "papermill": {
     "duration": 54.426054,
     "end_time": "2023-07-18T13:52:53.146768",
     "exception": false,
     "start_time": "2023-07-18T13:51:58.720714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "test_dataset, _ = generate_tf_dataset(\n",
    "    test_captions_df.sample(n=n_samples), tokenizer=tokenizer, n_vocab=n_vocab, batch_size=n_samples, training=False\n",
    ")\n",
    "\n",
    "def generate_caption(model, image_input, tokenizer, n_samples):\n",
    "    # 2 -> [START]\n",
    "    batch_tokens = np.repeat(np.array([[2]]), n_samples, axis=0)\n",
    "    \n",
    "    for i in range(30):\n",
    "        if np.all(batch_tokens[:,-1] == 3):\n",
    "            break\n",
    "            \n",
    "        position_input = tf.repeat(tf.reshape(tf.range(i+1),[1,-1]), n_samples, axis=0)\n",
    "        probs = full_model((image_input, batch_tokens, position_input)).numpy()\n",
    "        batch_tokens = np.argmax(probs, axis=-1)\n",
    "    \n",
    "    predicted_text = []\n",
    "    for sample_tokens in batch_tokens:\n",
    "        sample_predicted_token_ids = sample_tokens.ravel()\n",
    "        sample_predicted_tokens = []\n",
    "        for wid in sample_predicted_token_ids:\n",
    "            sample_predicted_tokens.append(tokenizer.id_to_token(wid))\n",
    "            if wid == 3:\n",
    "                break\n",
    "        sample_predicted_text = \" \".join([tok for tok in sample_predicted_tokens])\n",
    "        sample_predicted_text = sample_predicted_text.replace(\" ##\", \"\")\n",
    "        predicted_text.append(sample_predicted_text)\n",
    "    \n",
    "    return predicted_text\n",
    "    \n",
    "    \n",
    "for batch in test_dataset.take(1):\n",
    "    (batch_image_input, _, _), batch_true_caption = batch\n",
    "\n",
    "batch_predicted_text = generate_caption(full_model, batch_image_input, tokenizer, n_samples)\n",
    "\n",
    "fig, axes = plt.subplots(n_samples, 2, figsize=(8,30))\n",
    "\n",
    "for i,(sample_image_input, sample_true_caption, sample_predicated_caption) in enumerate(zip(batch_image_input, batch_true_caption, batch_predicted_text)):\n",
    "    \n",
    "    sample_true_caption_tokens  = [tokenizer.id_to_token(wid) for wid in sample_true_caption.numpy().ravel()]\n",
    "    \n",
    "    sample_true_text = []\n",
    "    for tok in sample_true_caption_tokens:\n",
    "        sample_true_text.append(tok)\n",
    "        if tok == '[END]':\n",
    "            break\n",
    "    \n",
    "    sample_true_text = \" \".join(sample_true_text).replace(\" ##\", \"\")\n",
    "    axes[i][0].imshow(((sample_image_input.numpy()+1.0)/2.0))\n",
    "    axes[i][0].axis('off')\n",
    "    \n",
    "    true_annotation = f\"TRUE: {sample_true_text}\"\n",
    "    predicted_annotation = f\"PRED: {sample_predicated_caption}\"\n",
    "    axes[i][1].text(0, 0.75, true_annotation, fontsize=18)\n",
    "    axes[i][1].text(0, 0.25, predicted_annotation, fontsize=18)\n",
    "    axes[i][1].axis('off')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15275.585807,
   "end_time": "2023-07-18T13:52:57.478752",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-18T09:38:21.892945",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
