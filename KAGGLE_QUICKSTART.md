```markdown
# H∆∞·ªõng D·∫´n Nhanh: Hu·∫•n Luy·ªán Image Captioning Y T·∫ø Trong 4 Ng√†y
## T·ªëi ∆∞u cho Kaggle T4 x2 GPU

---

## üìã T·ªïng Quan

**M·ª•c ti√™u**: X√¢y d·ª±ng h·ªá th·ªëng Medical Image Captioning gi·∫£m thi·ªÉu hallucination trong 4 ng√†y v·ªõi r√†ng bu·ªôc t√†i nguy√™n.

**T√†i nguy√™n**:
- 2x Tesla T4 GPU (16GB VRAM m·ªói card) tr√™n Kaggle
- ~30 gi·ªù GPU time / tu·∫ßn

**Dataset**: IU X-Ray (~7,470 ·∫£nh X-quang ng·ª±c)

**Chi·∫øn l∆∞·ª£c**: 
1. **Kh√¥ng train from scratch** - S·ª≠ d·ª•ng pre-trained VLM (Vision-Language Model)
2. **LoRA fine-tuning** - Ch·ªâ train m·ªôt ph·∫ßn nh·ªè parameters
3. **Keyword-based reward** - Thay v√¨ RadGraph ph·ª©c t·∫°p

---

## üóìÔ∏è L·ªãch Tr√¨nh 4 Ng√†y

### **Ng√†y 1 (8 gi·ªù): Baseline - Cross-Entropy Training**

**M·ª•c ti√™u**: C√≥ m·ªôt model baseline ho·∫°t ƒë·ªông t·ªët

#### B∆∞·ªõc 1: Setup m√¥i tr∆∞·ªùng tr√™n Kaggle

```bash
# Tr√™n Kaggle Notebook
# Settings -> Accelerator -> GPU T4 x2
# Settings -> Internet -> ON

# Clone repository
!git clone https://github.com/your-repo/medical-captioning.git
%cd medical-captioning

# Install dependencies
!pip install transformers peft bitsandbytes -q
!pip install pycocoevalcap nltk -q
!pip install accelerate einops -q
```

#### B∆∞·ªõc 2: Download IU X-Ray dataset

```bash
# Option 1: From Kaggle Dataset
# Add "IU X-Ray" dataset v√†o notebook (n·∫øu c√≥ s·∫µn)

# Option 2: Download t·ª´ OpenI
!wget https://openi.nlm.nih.gov/imgs/collections/NLMCXR_png.tgz
!tar -xzf NLMCXR_png.tgz -C data/

# C·∫•u tr√∫c mong ƒë·ª£i:
# data/IU_XRAY/
#   ‚îú‚îÄ‚îÄ images/
#   ‚îî‚îÄ‚îÄ indiana_reports.csv
```

#### B∆∞·ªõc 3: Ch·∫°y training Ng√†y 1

```bash
# S·ª≠ d·ª•ng ViT-GPT2 (nhanh, nh·∫π)
python 4Day_Scripts/day1_baseline.py \
    --data_dir data/IU_XRAY \
    --model_type vit-gpt2 \
    --epochs 10 \
    --batch_size 16 \
    --lr 5e-5 \
    --use_lora \
    --use_fp16 \
    --use_multi_gpu

# Ho·∫∑c s·ª≠ d·ª•ng BLIP-2 (t·ªët h∆°n nh∆∞ng ch·∫≠m h∆°n)
python 4Day_Scripts/day1_baseline.py \
    --data_dir data/IU_XRAY \
    --model_type blip2 \
    --epochs 10 \
    --batch_size 8 \
    --lr 5e-5 \
    --use_8bit \
    --use_lora
```

**Th·ªùi gian d·ª± ki·∫øn**: 4-6 gi·ªù

**K·∫øt qu·∫£ mong ƒë·ª£i**:
- BLEU-4: ~0.15-0.20
- CIDEr: ~0.30-0.50
- Checkpoint saved: `checkpoints/day1_baseline/best_model.pt`

#### Troubleshooting Ng√†y 1

**L·ªói OOM (Out of Memory)**:
```bash
# Gi·∫£m batch size
--batch_size 8

# Ho·∫∑c gi·∫£m sequence length
--max_length 64
```

**Training qu√° ch·∫≠m**:
```bash
# Gi·∫£m s·ªë epochs
--epochs 5

# Ho·∫∑c d√πng ViT-GPT2 thay v√¨ BLIP-2
--model_type vit-gpt2
```

---

### **Ng√†y 2 (8 gi·ªù): SCST - Reinforcement Learning**

**M·ª•c ti√™u**: C·∫£i thi·ªán factual accuracy, gi·∫£m hallucination

#### B∆∞·ªõc 1: Ki·ªÉm tra checkpoint t·ª´ Ng√†y 1

```bash
# Verify checkpoint exists
ls -lh checkpoints/day1_baseline/best_model.pt
```

#### B∆∞·ªõc 2: Ch·∫°y SCST training

```bash
python 4Day_Scripts/day2_scst.py \
    --data_dir data/IU_XRAY \
    --model_type vit-gpt2 \
    --pretrained_checkpoint checkpoints/day1_baseline/best_model.pt \
    --epochs 5 \
    --batch_size 8 \
    --lr 1e-6 \
    --cider_weight 1.0 \
    --keyword_weight 0.5 \
    --hallucination_penalty 0.3
```

**‚ö†Ô∏è L∆∞u √Ω quan tr·ªçng cho RL**:

1. **Learning rate ph·∫£i r·∫•t nh·ªè** (1e-6, kh√¥ng l·ªõn h∆°n 5e-6)
2. **Batch size nh·ªè h∆°n** (8 thay v√¨ 16) v√¨ RL t·ªën b·ªô nh·ªõ h∆°n
3. **S·ªë epochs √≠t h∆°n** (5 thay v√¨ 10) v√¨ RL d·ªÖ overfit
4. **Monitor rewards**: N·∫øu reward gi·∫£m li√™n t·ª•c, STOP ngay!

**Th·ªùi gian d·ª± ki·∫øn**: 6-8 gi·ªù

**K·∫øt qu·∫£ mong ƒë·ª£i**:
- CIDEr improvement: +0.05-0.15
- Keyword F1 improvement: +3-8%
- Hallucination rate reduction: -5-10%

#### Ki·ªÉm tra k·∫øt qu·∫£ SCST

```python
# So s√°nh Baseline vs SCST
import json

with open("checkpoints/day1_baseline/history.json") as f:
    baseline = json.load(f)

with open("checkpoints/day2_scst/history.json") as f:
    scst = json.load(f)

print(f"Baseline CIDEr: {baseline['best_cider']:.4f}")
print(f"SCST CIDEr: {scst['best_cider']:.4f}")
print(f"Improvement: {scst['best_cider'] - baseline['best_cider']:+.4f}")
```

#### RL Troubleshooting

**Rewards tr·ªü n√™n r·∫•t √¢m** (< -1.0):
```bash
# RL ƒëang diverge, gi·∫£m learning rate
--lr 5e-7

# Ho·∫∑c stop training v√† d√πng checkpoint t·ªët nh·∫•t t·ª´ Ng√†y 1
```

**Training qu√° ch·∫≠m**:
```bash
# Gi·∫£m epochs
--epochs 3

# TƒÉng batch size m·ªôt ch√∫t (n·∫øu VRAM c√≤n d∆∞)
--batch_size 12
```

---

### **Ng√†y 3 (4 gi·ªù): Ensemble v√† Analysis**

**M·ª•c ti√™u**: K·∫øt h·ª£p nhi·ªÅu models ƒë·ªÉ tƒÉng performance

#### B∆∞·ªõc 1: Ensemble evaluation

```bash
python 4Day_Scripts/day3_ensemble.py \
    --data_dir data/IU_XRAY \
    --model_type vit-gpt2 \
    --checkpoints \
        checkpoints/day1_baseline/best_model.pt \
        checkpoints/day2_scst/best_model.pt \
    --model_names baseline scst \
    --ensemble_method voting \
    --evaluate_test
```

**Th·ªùi gian d·ª± ki·∫øn**: 2-3 gi·ªù

**K·∫øt qu·∫£ mong ƒë·ª£i**:
- Ensemble th∆∞·ªùng c·∫£i thi·ªán +0.02-0.05 CIDEr so v·ªõi single model

#### B∆∞·ªõc 2: Th·ª≠ nghi·ªám (n·∫øu c√≤n th·ªùi gian)

N·∫øu c√≤n th·ªùi gian, c√≥ th·ªÉ th·ª≠:

**Option A**: Train th√™m m·ªôt model v·ªõi hyperparameter kh√°c
```bash
python 4Day_Scripts/day1_baseline.py \
    --epochs 8 \
    --lr 3e-5 \
    --checkpoint_dir checkpoints/day3_variant
```

**Option B**: Fine-tune th√™m v·ªõi hybrid loss
```python
# K·∫øt h·ª£p CE + SCST reward trong m·ªôt epoch
# (code advanced - xem trainer.py)
```

---

### **Ng√†y 4 (4 gi·ªù): Final Evaluation v√† Report**

**M·ª•c ti√™u**: ƒê√°nh gi√° to√†n di·ªán v√† vi·∫øt b√°o c√°o

#### B∆∞·ªõc 1: Comprehensive evaluation

```bash
python 4Day_Scripts/day4_evaluate.py \
    --data_dir data/IU_XRAY \
    --model_type vit-gpt2 \
    --checkpoints \
        checkpoints/day1_baseline/best_model.pt \
        checkpoints/day2_scst/best_model.pt \
    --model_names baseline scst \
    --output_dir results/final
```

**Output**:
- `results/final/FINAL_REPORT.md`: B√°o c√°o chi ti·∫øt
- `results/final/evaluation_results.json`: Metrics s·ªë li·ªáu
- Best/worst examples cho qualitative analysis

**Th·ªùi gian d·ª± ki·∫øn**: 1-2 gi·ªù

#### B∆∞·ªõc 2: Visualize results

```python
import json
import matplotlib.pyplot as plt

# Load results
with open("results/final/evaluation_results.json") as f:
    results = json.load(f)

# Plot comparison
models = list(results.keys())
ciders = [results[m]["CIDEr"] for m in models]
kw_f1s = [results[m]["Keyword_F1"] for m in models]

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

ax1.bar(models, ciders)
ax1.set_ylabel("CIDEr")
ax1.set_title("CIDEr Comparison")

ax2.bar(models, kw_f1s)
ax2.set_ylabel("Keyword F1")
ax2.set_title("Keyword F1 Comparison")

plt.tight_layout()
plt.savefig("results/final/comparison.png", dpi=150)
```

#### B∆∞·ªõc 3: Vi·∫øt b√°o c√°o (2 gi·ªù)

1. **Quantitative results**: B·∫£ng so s√°nh metrics
2. **Qualitative analysis**: Best/worst examples
3. **Discussion**: 
   - SCST c√≥ gi√∫p √≠ch kh√¥ng?
   - Hallucination c√≥ gi·∫£m kh√¥ng?
   - Keyword matching c√≥ h·ª£p l√Ω kh√¥ng?
4. **Conclusion**: Lessons learned

---

## üìä Expected Results (Tham kh·∫£o)

| Model | BLEU-4 | METEOR | ROUGE-L | CIDEr | Keyword F1 | Hallucination |
|-------|--------|--------|---------|-------|------------|---------------|
| Baseline (CE) | 0.18 | 0.24 | 0.42 | 0.45 | 0.62 | 0.28 |
| SCST (RL) | 0.20 | 0.26 | 0.44 | 0.52 | 0.68 | 0.21 |
| Ensemble | 0.21 | 0.27 | 0.45 | 0.54 | 0.70 | 0.19 |

**Improvement t·ª´ Baseline ‚Üí SCST**:
- CIDEr: +15%
- Keyword F1: +10%
- Hallucination: -25%

---

## üí° Tips Quan Tr·ªçng Cho Kaggle

### 1. Qu·∫£n l√Ω GPU Time

Kaggle cho ~30 gi·ªù GPU/tu·∫ßn. **L∆∞u checkpoint th∆∞·ªùng xuy√™n!**

```bash
# Auto-save m·ªói epoch
--eval_every 1

# Checkpoint directory persistent
!mkdir -p /kaggle/working/checkpoints
!cp -r checkpoints/* /kaggle/working/
```

### 2. TƒÉng t·ªëc Training

```bash
# Mixed precision (B·∫ÆT BU·ªòC)
--use_fp16

# Multi-GPU
--use_multi_gpu

# DataLoader workers
--num_workers 4
```

### 3. Gi·∫£m VRAM Usage

```bash
# ViT-GPT2 (nh·∫π nh·∫•t)
--model_type vit-gpt2

# 8-bit quantization (BLIP-2)
--use_8bit

# Gradient accumulation (n·∫øu batch size qu√° nh·ªè)
--gradient_accumulation_steps 2
```

### 4. Debug Nhanh

```bash
# Test v·ªõi 1 epoch ƒë·∫ßu
--epochs 1

# Test v·ªõi subset nh·ªè
--max_samples 100
```

---

## üö® Common Issues & Solutions

### Issue 1: "CUDA Out of Memory"

**Solution**:
```bash
# Gi·∫£m batch size
--batch_size 4

# Gi·∫£m sequence length
--max_length 64

# S·ª≠ d·ª•ng gradient checkpointing (trong trainer.py)
```

### Issue 2: "RL rewards dropping"

**Solution**:
```bash
# STOP training ngay!
# Gi·∫£m learning rate
--lr 5e-7

# Ho·∫∑c quay l·∫°i baseline checkpoint
```

### Issue 3: "Training qu√° ch·∫≠m"

**Solution**:
```bash
# D√πng ViT-GPT2 thay v√¨ BLIP-2
--model_type vit-gpt2

# Gi·∫£m num_workers n·∫øu CPU bottleneck
--num_workers 2

# Gi·∫£m eval frequency
--eval_every 5
```

### Issue 4: "IU X-Ray data not found"

**Solution**:
```bash
# Download manual t·ª´ OpenI
wget https://openi.nlm.nih.gov/imgs/collections/NLMCXR_png.tgz

# Ho·∫∑c d√πng Kaggle dataset (search "IU X-Ray")
# Add dataset to notebook
```

---

## üìÅ C·∫•u Tr√∫c Project

```
medical_img_captioning_train/
‚îú‚îÄ‚îÄ Fast_Models/
‚îÇ   ‚îú‚îÄ‚îÄ blip2_wrapper.py          # BLIP-2 with LoRA/8-bit
‚îÇ   ‚îî‚îÄ‚îÄ vit_gpt2_wrapper.py       # ViT-GPT2 (faster)
‚îú‚îÄ‚îÄ Fast_Data/
‚îÇ   ‚îî‚îÄ‚îÄ iu_xray_loader.py         # IU X-Ray dataset
‚îú‚îÄ‚îÄ Fast_Rewards/
‚îÇ   ‚îî‚îÄ‚îÄ keyword_reward.py         # Keyword-based reward
‚îú‚îÄ‚îÄ Fast_Training/
‚îÇ   ‚îî‚îÄ‚îÄ trainer.py                # CE + SCST trainer
‚îú‚îÄ‚îÄ 4Day_Scripts/
‚îÇ   ‚îú‚îÄ‚îÄ day1_baseline.py          # Day 1: CE training
‚îÇ   ‚îú‚îÄ‚îÄ day2_scst.py              # Day 2: RL training
‚îÇ   ‚îú‚îÄ‚îÄ day3_ensemble.py          # Day 3: Ensemble
‚îÇ   ‚îî‚îÄ‚îÄ day4_evaluate.py          # Day 4: Evaluation
‚îî‚îÄ‚îÄ KAGGLE_QUICKSTART.md          # This file
```

---

## ‚úÖ Checklist

### Before Starting:
- [ ] Kaggle account v·ªõi GPU quota
- [ ] IU X-Ray dataset downloaded
- [ ] Dependencies installed
- [ ] GPU T4 x2 activated

### Day 1:
- [ ] Baseline training complete (4-6 gi·ªù)
- [ ] Checkpoint saved: `day1_baseline/best_model.pt`
- [ ] CIDEr ~0.3-0.5

### Day 2:
- [ ] SCST training complete (6-8 gi·ªù)
- [ ] Rewards improving (not dropping)
- [ ] CIDEr improvement +0.05-0.15

### Day 3:
- [ ] Ensemble evaluation done
- [ ] Best model selected

### Day 4:
- [ ] Final evaluation complete
- [ ] Report written
- [ ] Results saved to `results/final/`

---

## üéØ Success Criteria

**Minimum viable**:
- BLEU-4 > 0.15
- CIDEr > 0.40
- Keyword F1 > 0.60
- Hallucination < 0.30

**Good result**:
- BLEU-4 > 0.20
- CIDEr > 0.50
- Keyword F1 > 0.65
- Hallucination < 0.25

**Excellent result**:
- BLEU-4 > 0.25
- CIDEr > 0.60
- Keyword F1 > 0.70
- Hallucination < 0.20

---

## üìö References

- **IU X-Ray**: Demner-Fushman et al., 2016
- **BLIP-2**: Li et al., 2023
- **SCST**: Rennie et al., 2017
- **LoRA**: Hu et al., 2021

---

## üÜò Support

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ:
1. Check `TROUBLESHOOTING.md`
2. Review error messages carefully
3. Search Kaggle discussions
4. Check GPU usage: `nvidia-smi`

---

**Good luck! üöÄ**

Nh·ªõ r·∫±ng: **4 ng√†y l√† r·∫•t ng·∫Øn**. T·∫≠p trung v√†o l√†m cho code ch·∫°y ƒë∆∞·ª£c tr∆∞·ªõc, t·ªëi ∆∞u sau!
```
